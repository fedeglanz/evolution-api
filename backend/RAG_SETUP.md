# ğŸ§  RAG (Retrieval Augmented Generation) Setup Guide

## ğŸ“‹ Resumen

El sistema RAG implementa bÃºsqueda semÃ¡ntica inteligente usando embeddings de OpenAI y pgvector para proporcionar contexto relevante a los bots de WhatsApp.

## ğŸ”§ ConfiguraciÃ³n Requerida

### 1. Variables de Entorno

AÃ±adir a tu archivo `.env`:

```bash
# ğŸ”¥ RAG & AI CONFIGURATION (REQUERIDO)
OPENAI_API_KEY=sk-your-openai-api-key-here

# RAG SETTINGS (Opcional - se usan valores por defecto)
RAG_SIMILARITY_THRESHOLD=0.7
RAG_MAX_CONTEXT_CHUNKS=5
RAG_MAX_CONTEXT_TOKENS=2000
RAG_EMBEDDING_MODEL=text-embedding-3-small
RAG_EMBEDDING_DIMENSIONS=1536
```

### 2. Base de Datos PostgreSQL

Ejecutar la migraciÃ³n RAG:

```sql
-- Ejecutar el archivo: migrations/007_rag_embeddings.sql
-- Esto instala pgvector y crea las tablas/funciones necesarias
```

### 3. Dependencias de Node.js

Ya instaladas:
- `openai` - SDK oficial de OpenAI
- `tiktoken` - TokenizaciÃ³n para cÃ¡lculo de costos

## ğŸš€ Testing del Sistema

### Endpoints de Prueba Disponibles:

#### 1. Verificar Estado RAG
```bash
GET /api/knowledge/rag/status
```
Devuelve el estado de embeddings para tu empresa.

#### 2. Migrar Knowledge Existente
```bash
POST /api/knowledge/rag/migrate
```
Genera embeddings para todo el knowledge existente.

#### 3. Probar BÃºsqueda SemÃ¡ntica
```bash
POST /api/knowledge/rag/test-search
Content-Type: application/json

{
  "query": "Â¿CÃ³mo funciona el sistema de pagos?",
  "botId": "uuid-opcional-del-bot",
  "similarityThreshold": 0.7,
  "maxResults": 5
}
```

#### 4. Probar GeneraciÃ³n de Embeddings
```bash
POST /api/knowledge/rag/test-embeddings
Content-Type: application/json

{
  "text": "Este es un texto de prueba para generar embeddings",
  "provider": "openai",
  "model": "text-embedding-3-small"
}
```

#### 5. Ver Analytics RAG
```bash
GET /api/knowledge/rag/analytics
GET /api/knowledge/rag/analytics/{botId}
```

## ğŸ”„ Flujo de Funcionamiento

### 1. CreaciÃ³n AutomÃ¡tica de Embeddings
- Al crear/actualizar knowledge â†’ se generan embeddings automÃ¡ticamente
- Al subir archivos â†’ se extraen embeddings del contenido

### 2. BÃºsqueda Inteligente
- Query del usuario â†’ embedding del query
- BÃºsqueda de similitud en pgvector â†’ chunks relevantes
- ConstrucciÃ³n de contexto optimizado â†’ respuesta del bot

### 3. Multi-Tenant Security
- Todos los embeddings incluyen `company_id`
- Funciones SQL con `SECURITY DEFINER`
- BÃºsquedas aisladas por empresa/bot

## ğŸ“Š Arquitectura del Sistema

```
User Query â†’ EmbeddingService â†’ RAGService â†’ PostgreSQL pgvector
                    â†“
OpenAI API â†’ Vector(1536) â†’ Cosine Similarity Search
                    â†“
Knowledge Chunks â†’ Context Builder â†’ Bot Response
```

## ğŸ” Funciones PostgreSQL Creadas

- `search_knowledge_embeddings()` - BÃºsqueda por empresa
- `search_bot_knowledge_embeddings()` - BÃºsqueda por bot especÃ­fico
- `get_embeddings_stats()` - EstadÃ­sticas de embeddings
- `chunk_text_for_embeddings()` - Chunking inteligente de texto

## ğŸ’° Costos de OpenAI

### Modelos de Embeddings:
- `text-embedding-3-small`: $0.00002 / 1K tokens
- `text-embedding-3-large`: $0.00013 / 1K tokens

### EstimaciÃ³n:
- Documento de 1000 palabras â‰ˆ 1333 tokens
- Cost per documento â‰ˆ $0.000027 (small) o $0.00017 (large)

## ğŸ›Ÿ Troubleshooting

### Error: "pgvector extension not found"
```sql
-- En PostgreSQL como superuser:
CREATE EXTENSION IF NOT EXISTS vector;
```

### Error: "OpenAI API key not configured"
```bash
# Verificar variable de entorno:
echo $OPENAI_API_KEY
```

### Error: "Insufficient similarity results"
- Reducir `similarityThreshold` en las bÃºsquedas
- Verificar que hay knowledge con embeddings generados

### Performance Issues
- Verificar Ã­ndices: `idx_embeddings_vector_cosine`
- Monitorear token usage en OpenAI dashboard
- Ajustar `RAG_MAX_CONTEXT_TOKENS` si es necesario

## ğŸ“ˆ Monitoreo

### MÃ©tricas Importantes:
- Embedding generation time
- Search similarity scores
- Context token usage
- API call frequency

### Logs a Monitorear:
```bash
# Buscar en logs:
grep "EmbeddingService" backend.log
grep "RAGService" backend.log
grep "OpenAI" backend.log
```

## âš¡ Optimizaciones Futuras

1. **Cache de Embeddings**: Redis cache para queries frecuentes
2. **Batch Processing**: Procesar mÃºltiples embeddings en paralelo
3. **Embedding Providers**: AÃ±adir Cohere, Hugging Face, etc.
4. **Vector Database**: Considerar Pinecone, Weaviate para escalamiento
5. **Smart Chunking**: Chunking basado en estructura de documento

## ğŸ” Seguridad

- âœ… Multi-tenant isolation a nivel de base de datos
- âœ… Validation de ownership de bots
- âœ… Rate limiting en OpenAI API calls
- âœ… EncriptaciÃ³n de embeddings (opcional, configurar si necesario)

---

**Â¿Dudas?** Verificar logs del sistema o usar los endpoints de testing para diagnosticar problemas. 